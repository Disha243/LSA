{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"id":"WQLig-6w3S4j","executionInfo":{"status":"error","timestamp":1604135295257,"user_tz":-60,"elapsed":4135,"user":{"displayName":"disha k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmFVCj9rXL63OplNVG51KMhyxzE1RCZ8o16KYZ=s64","userId":"09918487182590367361"}},"outputId":"3e9dd0f1-3e41-44ed-92fd-3f87e1514144","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["import numpy as np\n","import torch\n","import nibabel as nib\n","\n","from torchio.data.image import Image\n","import torchio\n","\n","import h5py as h5\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torchio.data.subject import Subject"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0513a9f53178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnibabel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchio'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"s8avp4aO2Gum"},"source":["class H5DSImage(Image):\n","    def __init__(self, h5DS=None, lazypatch=True, imtype=torchio.INTENSITY, **kwargs):\n","        kwargs['path'] = ''\n","        kwargs['type'] = imtype\n","        super().__init__(**kwargs)\n","        self.h5DS = h5DS\n","        self.lazypatch = lazypatch\n","        if not self.lazypatch:\n","            self.load()\n","\n","    def load(self) -> None:\n","        if self._loaded:\n","            return\n","        if self.lazypatch:\n","            tensor, affine = self.h5DS, np.eye(4)\n","        else:\n","            tensor, affine = self.read_and_check_h5(self.h5DS)\n","        self[torchio.DATA] = tensor\n","        self[torchio.AFFINE] = affine\n","        self._loaded = True\n","\n","    @property\n","    def spatial_shape(self):\n","        if self.lazypatch:\n","            return self.shape\n","        else:\n","            return self.shape[1:]\n","\n","    def crop(self, index_ini, index_fin):\n","        new_origin = nib.affines.apply_affine(self.affine, index_ini)\n","        new_affine = self.affine.copy()\n","        new_affine[:3, 3] = new_origin\n","        i0, j0, k0 = index_ini\n","        i1, j1, k1 = index_fin\n","        if len(self.data.shape) == 4:\n","            patch = self.data[:, i0:i1, j0:j1, k0:k1]\n","        else:\n","            patch = np.expand_dims(self.data[i0:i1, j0:j1, k0:k1], 0)\n","        if not isinstance(self.data, torch.Tensor):\n","            patch = torch.from_numpy(patch)\n","        kwargs = dict(\n","            tensor=patch,\n","            affine=new_affine,\n","            type=self.type,\n","            path=self.path,\n","            h5DS=self.h5DS\n","        )\n","        for key, value in self.items():\n","            if key in torchio.data.image.PROTECTED_KEYS: continue\n","            kwargs[key] = value  \n","        return self.__class__(**kwargs)\n","\n","    def read_and_check_h5(self, h5DS):\n","        tensor, affine = torch.from_numpy(h5DS[()]).unsqueeze(0), np.eye(4)\n","        tensor = super().parse_tensor_shape(tensor)\n","        if self.channels_last:\n","            tensor = tensor.permute(3, 0, 1, 2)\n","        if self.check_nans and torch.isnan(tensor).any():\n","            warnings.warn(f'NaNs found in file \"{path}\"')\n","        return tensor, affine\n","\n","\n","class MoodTrainSet(Dataset):\n","    def __init__(self, indices=None, region='brain', data_path='MOOD_train.h5', torchiosub=True, lazypatch=True, preload=False):\n","        self.h5 = h5.File(data_path, 'r', swmr=True)\n","        self.samples = []\n","        if indices:\n","            self.samples = [self.h5[region][str(i).zfill(5)]for i in indices]\n","            # self.samples2 = [self.h5[region][str(i).zfill(5)][:] for i in indices]\n","        else:\n","            self.samples = [self.h5[region][i] for i in list(self.h5[region])]\n","        if preload:\n","            print('Preloading MoodTrainSet')\n","            for i in range(len(self.samples)):\n","                self.samples[i] = self.samples[i][:]\n","        self.torchiosub = torchiosub\n","        self.lazypatch = lazypatch\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, item):\n","        if self.torchiosub:\n","            return Subject({'img':H5DSImage(self.samples[item], lazypatch=self.lazypatch)})\n","        else:\n","            return torch.from_numpy(self.samples[item][()]).unsqueeze(0)\n","\n","class MoodValSet(Dataset):\n","    def __init__(self, load_abnormal=True, load_normal=True, loadASTrain=False, data_path='MOOD_val.h5', torchiosub=True, lazypatch=True, preload=False):\n","        self.h5 = h5.File(data_path, 'r', swmr=True)\n","        self.samples = []\n","        if load_abnormal:\n","            self.samples+=[(self.h5['abnormal'][i], self.h5['abnormal_mask'][i]) for i in list(self.h5['abnormal'])]\n","        if load_normal:\n","            self.samples+=[self.h5['normal'][i] for i in list(self.h5['normal'])]\n","        if preload:\n","            print('Preloading MoodValSet')\n","            for i in range(len(self.samples)):\n","                if len(self.samples[i]) == 2:\n","                    self.samples[i] = (self.samples[i][0][:], self.samples[i][1][:])\n","                else:\n","                    self.samples[i] = self.samples[i][:]\n","        self.loadASTrain = loadASTrain\n","        self.torchiosub = torchiosub\n","        self.lazypatch = lazypatch\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, item):\n","        if self.loadASTrain:\n","            if self.torchiosub:\n","                return Subject({'img':H5DSImage(self.samples[item][0], lazypatch=self.lazypatch)})\n","            else:\n","                return torch.from_numpy(self.samples[item][0][()]).unsqueeze(0)\n","        else:\n","            if self.torchiosub:\n","                if len(self.samples[item]) == 2:\n","                    return Subject({'img':H5DSImage(self.samples[item][0], lazypatch=self.lazypatch),\n","                                    'gt':H5DSImage(self.samples[item][1], lazypatch=self.lazypatch)})\n","                else:\n","                    return Subject({'img':H5DSImage(self.samples[item], lazypatch=self.lazypatch),\n","                                    'gt':H5DSImage(self.samples[item], lazypatch=self.lazypatch)}) #this is dirty. TODO\n","\n","            else:\n","                return (torch.from_numpy(self.samples[item][0][()]).unsqueeze(0), torch.from_numpy(self.samples[item][1][()]).unsqueeze(0))\n"],"execution_count":null,"outputs":[]}]}